{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb86af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fastf1.events as f1events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6290cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder\n",
    "cache_dir = os.path.expanduser(\"~/f1_cache\") #if on windows MUST contain directory \n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "#enable cache\n",
    "fastf1.Cache.enable_cache(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e83ca0",
   "metadata": {},
   "source": [
    "- The code below will allow initial acess to Fast1api to pull all data from 2019 to 2025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bede579",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cache_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fastf1\u001b[38;5;241m.\u001b[39mCache\u001b[38;5;241m.\u001b[39menable_cache(cache_dir) \u001b[38;5;66;03m#enable cache to prevent\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#set year range\u001b[39;00m\n\u001b[1;32m      4\u001b[0m YEARS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2026\u001b[39m)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'cache_dir' is not defined"
     ]
    }
   ],
   "source": [
    "fastf1.Cache.enable_cache(cache_dir) #enable cache to prevent\n",
    "\n",
    "\n",
    "YEARS = range(2019, 2026)  #set year range\n",
    "all_laps = [] #create dic to store laps\n",
    "\n",
    "for year in YEARS:\n",
    "    schedule = fastf1.get_event_schedule(year, include_testing=False)\n",
    "    non_sprint_events = schedule[schedule['EventFormat'] != 'sprint'] #exclude sprints for control \n",
    "\n",
    "    for i, event in non_sprint_events.iterrows():\n",
    "        round_num = event['RoundNumber']\n",
    "        event_name = event['EventName']\n",
    "\n",
    "        try:\n",
    "            session = fastf1.get_session(year, round_num, 'R') #races only; qualifying and practices are excluded\n",
    "            print(f\"Loading {year} Round {round_num} - {event_name}\")\n",
    "            session.load(telemetry=True)  \n",
    "            laps = session.laps.copy()\n",
    "            laps['RaceName'] = event_name\n",
    "            laps['Year'] = year\n",
    "            laps['PostRegulation'] = int(year >= 2022)\n",
    "\n",
    "            #merge weather data\n",
    "            weather = session.weather_data.copy()\n",
    "            laps['LapStartTimeSec'] = laps['LapStartTime'].dt.total_seconds()\n",
    "            weather['TimeSec'] = weather['Time'].dt.total_seconds()\n",
    "\n",
    "            laps = pd.merge_asof(\n",
    "                laps.sort_values('LapStartTimeSec'),\n",
    "                weather[['TimeSec', 'AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity']],\n",
    "                left_on='LapStartTimeSec',\n",
    "                right_on='TimeSec',\n",
    "                direction='nearest'\n",
    "            )\n",
    "\n",
    "            all_laps.append(laps)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped {event_name} ({year}) due to error: {e}\")\n",
    "\n",
    "#combine all datasets to one & export\n",
    "if all_laps:\n",
    "    final_df = pd.concat(all_laps, ignore_index=True)\n",
    "    final_df = final_df.dropna().reset_index(drop=True)\n",
    "    final_df.to_csv('laps_2020_2025_extended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to use the full lap into an aggregated race level data for RF and lap level for linear mixed model\n",
    "df = pd.read_csv('laps_2019_2025.csv')\n",
    "\n",
    "#convert time columns to timedelta and LapTime to seconds\n",
    "time_cols = ['LapTime', 'Time', 'LapStartTime']\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_timedelta(df[col], errors='coerce')\n",
    "df['LapTime_sec'] = df['LapTime'].dt.total_seconds()\n",
    "\n",
    "#drop rows with missing essential data\n",
    "df_cleaned = df.dropna(subset=['Position', 'DriverNumber', 'Year', 'RaceName', 'LapNumber', 'Driver', 'LapTime_sec']).copy()\n",
    "\n",
    "\n",
    "#convert to ints & rename cols\n",
    "df_cleaned['Position'] = pd.to_numeric(df_cleaned['Position']).astype(int)\n",
    "df_cleaned['LapNumber'] = pd.to_numeric(df_cleaned['LapNumber']).astype(int)\n",
    "df_cleaned['DriverNumber'] = pd.to_numeric(df_cleaned['DriverNumber']).astype(int)\n",
    "df_cleaned['RegulationEra'] = df_cleaned['PostRegulation'].astype(int)\n",
    "\n",
    "\"\"\"\n",
    "#Likely not be used\n",
    "#preping overtakes and lap level for mixed effects model below\n",
    "#--------------------------------------------------\n",
    "\n",
    "#sort the data for accurate shift operation\n",
    "df_cleaned = df_cleaned.sort_values(by=['Year', 'RaceName', 'DriverNumber', 'LapNumber'])\n",
    "\n",
    "#get prev position\n",
    "df_cleaned['PreviousPosition'] = df_cleaned.groupby(['Year', 'RaceName', 'DriverNumber'])['Position'].shift(1)\n",
    "\n",
    "#overtake condition is when current position < prev position and not during pitout (tire changes)\n",
    "overtake_mask = (\n",
    "    (df_cleaned['Position'] < df_cleaned['PreviousPosition']) &\n",
    "    (df_cleaned['PitOutTime'].isna())\n",
    ")\n",
    "df_cleaned['IsOvertake'] = overtake_mask\n",
    "\n",
    "#get all cols\n",
    "lap_lmem_cols = [\n",
    "    'Year', 'RaceName', 'Driver', 'DriverNumber', 'Team', 'LapNumber', 'LapTime_sec',\n",
    "    'Position', 'PreviousPosition', 'IsOvertake', 'Compound', 'TyreLife',\n",
    "    'AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity', 'TrackStatus', 'RegulationEra',\n",
    "    'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST'\n",
    "]\n",
    "\n",
    "df_lap_final = df_cleaned[lap_lmem_cols].copy()\n",
    "\n",
    "#drop rows missing essential lap-level fields before saving (avoid dropping on optional columns)\n",
    "df_lap_final = df_lap_final.dropna(subset=['Year', 'RaceName', 'Driver', 'DriverNumber', 'LapNumber', 'LapTime_sec']).reset_index(drop=True)\n",
    "lap_output_file = 'lap_data_for_lmem_final.csv'\n",
    "df_lap_final.to_csv(lap_output_file, index=False)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#race level aggregation for RF begins below\n",
    "#----------------------------------\n",
    "\n",
    "#overtake PER race\n",
    "overtake_count = df_cleaned[df_cleaned['IsOvertake']].groupby(\n",
    "    ['Year', 'RaceName', 'DriverNumber']\n",
    ").size().reset_index(name='Overtakes_Per_Race')\n",
    "\n",
    "#def comprehensive aggregation dictionary\n",
    "mean_cols = ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST','AirTemp', 'TrackTemp', 'WindSpeed', 'Humidity', 'TrackStatus']\n",
    "\n",
    "#define aggregatiion method\n",
    "agg_dict = {\n",
    "    'LapNumber': 'max',  #total laps completed\n",
    "    'IsPersonalBest': 'any',\n",
    "    'TyreLife': 'max',\n",
    "    'RegulationEra': 'first', #era constant per race\n",
    "    'LapTime': 'mean', #mean lap time (duration) per race-driver\n",
    "    'Compound': lambda x: x.loc[x.index.max()] if not x.empty else np.nan, # Final Compound\n",
    "    'Team': 'first',}\n",
    "for col in mean_cols:\n",
    "    agg_dict[col] = 'mean'\n",
    "\n",
    "\n",
    "#aggregate cleaned data\n",
    "df_aggregated = df_cleaned.groupby(['Year', 'RaceName', 'Driver', 'DriverNumber']).agg(agg_dict).reset_index()\n",
    "\n",
    "#merge overtakes\n",
    "df_aggregated = df_aggregated.merge(\n",
    "    overtake_count,\n",
    "    on=['Year', 'RaceName', 'DriverNumber'],\n",
    "    how='left'\n",
    ")\n",
    "df_aggregated['Overtakes_Per_Race'] = df_aggregated['Overtakes_Per_Race'].fillna(0).astype(int)\n",
    "\n",
    "#determine final position & race time\n",
    "idx = df_cleaned.groupby(['Year', 'RaceName', 'DriverNumber'])['LapNumber'].idxmax()\n",
    "final_laps = df_cleaned.loc[idx, ['Year', 'RaceName', 'DriverNumber', 'Position', 'Time']].copy()\n",
    "final_laps.rename(columns={'Position': 'FinalPosition', 'Time': 'FinalRaceTime'}, inplace=True)\n",
    "\n",
    "df_aggregated = df_aggregated.merge(\n",
    "    final_laps[['Year', 'RaceName', 'DriverNumber', 'FinalPosition', 'FinalRaceTime']],\n",
    "    on=['Year', 'RaceName', 'DriverNumber'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#save race level data\n",
    "df_aggregated.rename(columns={\n",
    "    'LapNumber': 'TotalLapsCompleted',\n",
    "    'LapTime': 'LapTime',\n",
    "    'Compound': 'FinalStintCompound',\n",
    "}, inplace=True)\n",
    "\n",
    "#rename mean columns to indicate aggregation type and round\n",
    "for col in mean_cols:\n",
    "    df_aggregated.rename(columns={col: f'Mean_{col}'}, inplace=True)\n",
    "df_aggregated[[f'Mean_{col}' for col in mean_cols]] = df_aggregated[[f'Mean_{col}' for col in mean_cols]].round(2)\n",
    "\n",
    "#convert Timedelta objects to total seconds for easier analysis\n",
    "df_aggregated['LapTime'] = df_aggregated['LapTime'].dt.total_seconds()\n",
    "df_aggregated['FinalRaceTime'] = df_aggregated['FinalRaceTime'].dt.total_seconds()\n",
    "\n",
    "#save to csv\n",
    "race_output_file = 'race_data_for_rf.csv'\n",
    "df_aggregated.to_csv(race_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
